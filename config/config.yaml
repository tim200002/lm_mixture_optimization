name: Test
train_data: [["Books", "/media/ssd1/tim/dolma_v1.6_small/tokenized/book/train/2048-v1/0/manifest.jsonl"], ["C4", "/media/ssd1/tim/dolma_v1.6_small/tokenized/c4/train/2048-v1/0/manifest.jsonl"], ["CC", "/media/ssd1/tim/dolma_v1.6_small/tokenized/cc_en_head/train/2048-v1/0/manifest.jsonl"], ["Wiki", "/media/ssd1/tim/dolma_v1.6_small/tokenized/en_simple_wiki_v0/train/2048-v1/0/manifest.jsonl"], ["pes2o_v2", "/media/ssd1/tim/dolma_v1.6_small/tokenized/pes2o_v2/train/2048-v1/0/manifest.jsonl"], ["reddit", "/media/ssd1/tim/dolma_v1.6_small/tokenized/reddit-v5-dedupe-pii-nsfw-toxic/train/2048-v1/0/manifest.jsonl"], ["stack-v4", "/media/ssd1/tim/dolma_v1.6_small/tokenized/stack-v4-train/train/2048-v1/0/manifest.jsonl"]]
val_data: [["Books", "/media/ssd1/tim/dolma_v1.6_small/tokenized/book/val/2048-v1/0/manifest.jsonl"], ["C4", "/media/ssd1/tim/dolma_v1.6_small/tokenized/c4/val/2048-v1/0/manifest.jsonl"], ["CC", "/media/ssd1/tim/dolma_v1.6_small/tokenized/cc_en_head/val/2048-v1/0/manifest.jsonl"], ["Wiki", "/media/ssd1/tim/dolma_v1.6_small/tokenized/en_simple_wiki_v0/val/2048-v1/0/manifest.jsonl"], ["pes2o_v2", "/media/ssd1/tim/dolma_v1.6_small/tokenized/pes2o_v2/val/2048-v1/0/manifest.jsonl"], ["reddit", "/media/ssd1/tim/dolma_v1.6_small/tokenized/reddit-v5-dedupe-pii-nsfw-toxic/val/2048-v1/0/manifest.jsonl"], ["stack-v4", "/media/ssd1/tim/dolma_v1.6_small/tokenized/stack-v4-val/val/2048-v1/0/manifest.jsonl"]]
workspace: /root/code/mixture_optimization/logs
data_workspace: /media/ssd1/tim/data_workspace
delete_dataset_after_run: True

weight_selector:
  type: "random"
  no_weights: 7
  selector_config: {} # Config for specific weight selector

open_lm_config: # Config for openLM model, i.e model size, hyperparameters, ...
  complete_train_token_count: 800000000
  model: 50m
  workers: 2
  global_batch_size: 10
  log_every_n_steps: 50
  grad_clip_norm: 1
  lr: 0.0003
  warmup: 200
  wd: 0.1
  beta2: 0.95
  epochs: 10
  report_to: tensorboard
  data_key: txt
  lr_cooldown_end: 0.00003

data_mixing:
  no_workers: 8
  chunk_size: 2048
  

      